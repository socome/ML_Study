{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/socome/ML_study/blob/master/Lec05_2_exercise_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "X9MBmO8-hXLM",
        "colab_type": "code",
        "outputId": "9260875f-dbdb-46bf-accb-19903c906f44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/socome/ML_study.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML_study'...\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 68 (delta 27), reused 19 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (68/68), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ewNwRKlOx6BB",
        "colab_type": "code",
        "outputId": "3ea9bfed-9007-4402-e179-b4807610740c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "ls ML_study"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " data_01_test_score.csv            Lec04_1_3.ipynb\n",
            " data-03-diabetes.csv              Lec04_1_4.ipynb\n",
            " data_03_diabetes_train.csv        lec05_2_exercise.ipynb\n",
            " data_03_diabetes_train_test.csv   Lec05-2-exercise.ipynb\n",
            " data-04-zoo.csv                   Lec05_2_exercise_test.ipynb\n",
            " lab7_1_2.ipynb                   'Lec05-2(realdatatest).ipynb'\n",
            " lab7_1.ipynb                      Lec05.ipynb\n",
            " lab7_2.ipynb                      Lec6_2.ipynb\n",
            " Lec04_1_1.ipynb                   Lec6.ipynb\n",
            " Lec04_1_2.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DU48PEyUhYIQ",
        "colab_type": "code",
        "outputId": "987b9cd3-eef4-4b4d-ca7d-0eb046913232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8783
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "xy = np.loadtxt('ML_study/data_03_diabetes_train_test.csv', delimiter=',', dtype=np.float32)\n",
        "test_x_data = xy[:, 0:-1]\n",
        "test_y_data = xy[:, [-1]]\n",
        "\n",
        "filename_queue = tf.train.string_input_producer(['ML_study/data_03_diabetes_train.csv'], shuffle=False, name='filename_queue')\n",
        "reader = tf.TextLineReader()\n",
        "key, value = reader.read(filename_queue)\n",
        "record_defaults = [[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0]]\n",
        "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
        "\n",
        "train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
        "\n",
        "#placeholder for a tensor that will be always feed\n",
        "X = tf.placeholder(tf.float32, shape=[None, 8])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "W = tf.Variable(tf.random_normal([8,1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "#Hypothesis using sigmoid\n",
        "#if not using sigmoid (1., 1+tf.exp(tf.matmul(X,W) + b))\n",
        "hypothesis = tf.sigmoid(tf.matmul(X,W) + b)\n",
        "\n",
        "# cost/loss function\n",
        "cost = -tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis))\n",
        "\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
        "\n",
        "\n",
        "#cast => true(1)/false(0) \n",
        "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y), dtype=tf.float32))\n",
        "\n",
        "# parameters\n",
        "training_epochs = 15\n",
        "batch_size_a = 10\n",
        "#Launch graph\n",
        "with  tf.Session() as sess:\n",
        "\n",
        "    #initialize\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    coord = tf.train.Coordinator()\n",
        "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
        "\n",
        "    for epoch in range(training_epochs) :\n",
        "      avg_cost = 0\n",
        "      total_batch = int(524/batch_size_a)\n",
        "      for i in range(total_batch):\n",
        "          x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
        "          cost_val, _ = sess.run([cost,train], feed_dict={X:x_batch, Y:y_batch})  \n",
        "          avg_cost += cost_val / total_batch\n",
        "      \n",
        "      print(\"Cost:\",avg_cost) \n",
        "            \n",
        "    coord.request_stop()\n",
        "    coord.join(threads)\n",
        "    \n",
        "    #Accuracy report\n",
        "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X:test_x_data, Y:test_y_data})\n",
        "    print(\"\\n Hypothesis : \", h, \"\\nCorrect (Y) :\", c, \"\\nAccuracy:\", a)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost: 0.6949445645396527\n",
            "Cost: 0.66613048601609\n",
            "Cost: 0.6416659039946702\n",
            "Cost: 0.6219914905153787\n",
            "Cost: 0.6140670329332351\n",
            "Cost: 0.6047344522980544\n",
            "Cost: 0.5983325460782418\n",
            "Cost: 0.5918803988740994\n",
            "Cost: 0.5893007562710688\n",
            "Cost: 0.5853910371661186\n",
            "Cost: 0.5833575851642169\n",
            "Cost: 0.5809177555716954\n",
            "Cost: 0.5783728177730854\n",
            "Cost: 0.5743980121154053\n",
            "Cost: 0.5741233573510096\n",
            "\n",
            " Hypothesis :  [[0.88055414]\n",
            " [0.669889  ]\n",
            " [0.8651508 ]\n",
            " [0.58378476]\n",
            " [0.65441406]\n",
            " [0.79539174]\n",
            " [0.4983416 ]\n",
            " [0.75903696]\n",
            " [0.71572614]\n",
            " [0.71734697]\n",
            " [0.71984756]\n",
            " [0.8554943 ]\n",
            " [0.88085604]\n",
            " [0.38922244]\n",
            " [0.61766523]\n",
            " [0.6839332 ]\n",
            " [0.7825627 ]\n",
            " [0.535184  ]\n",
            " [0.8516939 ]\n",
            " [0.8205492 ]\n",
            " [0.7846479 ]\n",
            " [0.8493441 ]\n",
            " [0.884931  ]\n",
            " [0.58113253]\n",
            " [0.8543427 ]\n",
            " [0.6781021 ]\n",
            " [0.5972029 ]\n",
            " [0.5388558 ]\n",
            " [0.71377355]\n",
            " [0.27576664]\n",
            " [0.87267196]\n",
            " [0.6969239 ]\n",
            " [0.59952843]\n",
            " [0.78451264]\n",
            " [0.91774726]\n",
            " [0.78545666]\n",
            " [0.6395729 ]\n",
            " [0.55627173]\n",
            " [0.8499121 ]\n",
            " [0.7965181 ]\n",
            " [0.7195493 ]\n",
            " [0.8163925 ]\n",
            " [0.715515  ]\n",
            " [0.762743  ]\n",
            " [0.62463117]\n",
            " [0.86268806]\n",
            " [0.37875122]\n",
            " [0.5933876 ]\n",
            " [0.5815046 ]\n",
            " [0.5895745 ]\n",
            " [0.5307738 ]\n",
            " [0.6903058 ]\n",
            " [0.61033624]\n",
            " [0.7905762 ]\n",
            " [0.4914713 ]\n",
            " [0.60307163]\n",
            " [0.6973166 ]\n",
            " [0.5608414 ]\n",
            " [0.6062377 ]\n",
            " [0.8034243 ]\n",
            " [0.7570572 ]\n",
            " [0.8148194 ]\n",
            " [0.63321567]\n",
            " [0.28839526]\n",
            " [0.809544  ]\n",
            " [0.8778906 ]\n",
            " [0.67961115]\n",
            " [0.75514656]\n",
            " [0.8130355 ]\n",
            " [0.61126363]\n",
            " [0.7669777 ]\n",
            " [0.6447236 ]\n",
            " [0.43688083]\n",
            " [0.844465  ]\n",
            " [0.6017089 ]\n",
            " [0.81368554]\n",
            " [0.457108  ]\n",
            " [0.7797987 ]\n",
            " [0.74436396]\n",
            " [0.5818843 ]\n",
            " [0.50670815]\n",
            " [0.6649472 ]\n",
            " [0.50327134]\n",
            " [0.7165298 ]\n",
            " [0.6401571 ]\n",
            " [0.8482105 ]\n",
            " [0.6204568 ]\n",
            " [0.44709426]\n",
            " [0.8266604 ]\n",
            " [0.7989413 ]\n",
            " [0.51587176]\n",
            " [0.78225213]\n",
            " [0.8353114 ]\n",
            " [0.83042115]\n",
            " [0.53786457]\n",
            " [0.5710725 ]\n",
            " [0.71041423]\n",
            " [0.8177802 ]\n",
            " [0.552089  ]\n",
            " [0.60029715]\n",
            " [0.6983516 ]\n",
            " [0.770045  ]\n",
            " [0.48810968]\n",
            " [0.39832056]\n",
            " [0.7589782 ]\n",
            " [0.83565366]\n",
            " [0.73735183]\n",
            " [0.83143014]\n",
            " [0.62191784]\n",
            " [0.62828827]\n",
            " [0.6057994 ]\n",
            " [0.7345272 ]\n",
            " [0.76581025]\n",
            " [0.6839877 ]\n",
            " [0.66580576]\n",
            " [0.2723816 ]\n",
            " [0.44134012]\n",
            " [0.4815659 ]\n",
            " [0.81733865]\n",
            " [0.80548143]\n",
            " [0.67522424]\n",
            " [0.67804945]\n",
            " [0.8258814 ]\n",
            " [0.6205753 ]\n",
            " [0.7452313 ]\n",
            " [0.8516024 ]\n",
            " [0.8526592 ]\n",
            " [0.40060645]\n",
            " [0.5302436 ]\n",
            " [0.5311616 ]\n",
            " [0.5074577 ]\n",
            " [0.6634007 ]\n",
            " [0.82025224]\n",
            " [0.8109017 ]\n",
            " [0.51644933]\n",
            " [0.7507352 ]\n",
            " [0.48662606]\n",
            " [0.57856214]\n",
            " [0.87309957]\n",
            " [0.8177367 ]\n",
            " [0.8309234 ]\n",
            " [0.8092456 ]\n",
            " [0.31840426]\n",
            " [0.446939  ]\n",
            " [0.5625507 ]\n",
            " [0.67339367]\n",
            " [0.75673693]\n",
            " [0.86220586]\n",
            " [0.43341362]\n",
            " [0.63868076]\n",
            " [0.65869665]\n",
            " [0.7768037 ]\n",
            " [0.74365366]\n",
            " [0.58067304]\n",
            " [0.78903466]\n",
            " [0.6944729 ]\n",
            " [0.8497985 ]\n",
            " [0.5514282 ]\n",
            " [0.37707213]\n",
            " [0.7754482 ]\n",
            " [0.6438034 ]\n",
            " [0.7595179 ]\n",
            " [0.59658986]\n",
            " [0.60537964]\n",
            " [0.4696036 ]\n",
            " [0.74142426]\n",
            " [0.71246445]\n",
            " [0.7811354 ]\n",
            " [0.67901605]\n",
            " [0.77697074]\n",
            " [0.7738091 ]\n",
            " [0.74371   ]\n",
            " [0.7812028 ]\n",
            " [0.43472245]\n",
            " [0.6953532 ]\n",
            " [0.4042692 ]\n",
            " [0.82878953]\n",
            " [0.5778127 ]\n",
            " [0.72082734]\n",
            " [0.4814248 ]\n",
            " [0.53933895]\n",
            " [0.7680435 ]\n",
            " [0.313652  ]\n",
            " [0.5799021 ]\n",
            " [0.64503574]\n",
            " [0.80129886]\n",
            " [0.8319093 ]\n",
            " [0.83007735]\n",
            " [0.8837941 ]\n",
            " [0.76658684]\n",
            " [0.7967672 ]\n",
            " [0.8705186 ]\n",
            " [0.78452885]\n",
            " [0.82219887]\n",
            " [0.42446482]\n",
            " [0.50133437]\n",
            " [0.7575684 ]\n",
            " [0.7462678 ]\n",
            " [0.48122874]\n",
            " [0.66906804]\n",
            " [0.7561211 ]\n",
            " [0.8336232 ]\n",
            " [0.75729626]\n",
            " [0.6356926 ]\n",
            " [0.7780235 ]\n",
            " [0.89101595]\n",
            " [0.8766135 ]\n",
            " [0.58916473]\n",
            " [0.75246704]\n",
            " [0.7921694 ]\n",
            " [0.5173561 ]\n",
            " [0.33991385]\n",
            " [0.5665509 ]\n",
            " [0.7986692 ]\n",
            " [0.9136021 ]\n",
            " [0.57883257]\n",
            " [0.48491094]\n",
            " [0.55941534]\n",
            " [0.83096087]\n",
            " [0.7107218 ]\n",
            " [0.34026298]\n",
            " [0.49800763]\n",
            " [0.83756506]\n",
            " [0.58489734]\n",
            " [0.61990184]\n",
            " [0.8233663 ]\n",
            " [0.58446974]\n",
            " [0.8103597 ]\n",
            " [0.44201648]\n",
            " [0.5342905 ]\n",
            " [0.70454437]\n",
            " [0.7653272 ]\n",
            " [0.66436946]\n",
            " [0.79845405]\n",
            " [0.82474405]] \n",
            "Correct (Y) : [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] \n",
            "Accuracy: 0.7106383\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}